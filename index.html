<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="Sparse Imagination for Efficient Visual World Model Planning">
  <meta name="keywords" content="Robotics, World Model, Planning, Vision Transformer, Sparse Imagination">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Sparse Imagination for Efficient Visual World Model Planning</title>

  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag("js", new Date());
    gtag("config", "G-PYVRSFMDRL");
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="#">
        <span class="icon"><i class="fas fa-home"></i></span>
      </a>
    </div>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Sparse Imagination <br>for Efficient Visual World Model Planning</h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="mailto:nikriz@snu.ac.kr">Junha Chun</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="mailto:af1014@snu.ac.kr">Youngjoon Jeong</a><sup>2*</sup>,</span>
            <span class="author-block">
              <a href="mailto:taesup.kim@snu.ac.kr">Taesup Kim</a><sup>2†</sup>
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Department of Electrical and Computer Engineering, Seoul National University</span>
            <br>
            <span class="author-block"><sup>2</sup>Graduate School of Data Science, Seoul National University</span>
            <br>
            <span class="author-block" style="font-size: 0.9em; margin-top: 10px;">
              *Equal contribution, †Corresponding author
            </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2506.01392" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a class="external-link button is-normal is-rounded is-dark" disabled>
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            World model based planning has significantly improved decision-making in complex environments by enabling agents to simulate future states and make informed choices. This computational burden is particularly restrictive in robotics, where resources are severely constrained.
          </p>
          <p>
            We propose <strong>Sparse Imagination</strong>, which improves planning efficiency by using only a subset of visual tokens during latent rollouts. Our method trains a transformer world model with randomized grouped attention so it can robustly predict under dynamic token sparsity. Across simulation and real-world tasks, sparse imagination achieves strong speedups while preserving control performance.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/plan.png" alt="Sparse Imagination Overview"
           style="width: auto; max-height: 500px; display: block; margin: 0 auto;"
           onerror="this.style.display='none'; document.getElementById('teaser-placeholder').style.display='block';">
      <div id="teaser-placeholder" style="display:none; text-align:center; padding: 45px; background:#f5f5f5;">
        <p><strong>Missing teaser:</strong> <code>./static/images/fig_planning.png</code></p>
      </div>
      <h2 class="subtitle has-text-centered" style="margin-top: 15px;">
        <strong>World Model Planning with Sparse Imagination. </strong> 
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <p>
            The world model predicts future DINO patch tokens conditioned on past observations and actions. 
            During training, randomized grouped attention partitions tokens into groups and applies structured 
            attention masks, enabling robust prediction under arbitrary token subsets. During planning with world model, 
            we apply random token dropout with drop ratio <em>p</em>. 
            This reduces attention cost and allows a direct trade-off between speed and accuracy.
          </p>
        </div>

        
        <div class="hero-body">
          <img src="./static/images/train.png" alt="Randomized Grouped Attention"
              style="width: auto; max-height: 500px; display: block; margin: 0 auto;"
              onerror="this.style.display='none'; document.getElementById('teaser-placeholder').style.display='block';">
          <div id="teaser-placeholder" style="display:none; text-align:center; padding: 45px; background:#f5f5f5;">
            <p><strong>Missing teaser:</strong> <code>./static/images/train.png</code></p>
          </div>
          <h2 class="subtitle has-text-centered" style="margin-top: 15px;">
            <strong>Training with Randomized Grouped Attention Strategy.</strong> 
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Main Results</h2>

        <h3 class="title is-4">Test-Time Trajectory Optimization</h3>
        <div class="content has-text-justified">
          <p>
            Evaluated on Simulation environments; PointMaze, Wall, PushT, Block Pushing with MPC-CEM and Granular and Rope with CEM, 
            Moderate drop ratios (10-50%) preserve task performance while reducing planning time substantially. 
          </p>
        </div>

        <div class="columns is-centered">
          <div class="column is-10">
            <table class="table is-bordered is-striped is-hoverable is-fullwidth" style="font-size: 0.9em;">
              <thead>
                <tr class="has-background-light">
                  <th>Method</th>
                  <th>Avg. Success (%)</th>
                  <th>Avg. Planning Time (s/iter)</th>
                  <th>Avg. Change (%)</th>
                </tr>
              </thead>
              <tbody>
                <tr><td>Full</td><td>69.8</td><td>183.3</td><td>-</td></tr>
                <tr><td>CLS</td><td>50.7</td><td>71.0</td><td>-61.3%</td></tr>
                <tr class="has-background-info-light"><td>Drop 10%</td><td>74.1</td><td>166.3</td><td>-9.3%</td></tr>
                <tr class="has-background-info-light"><td>Drop 20%</td><td>69.6</td><td>150.0</td><td>-18.1%</td></tr>
                <tr class="has-background-info-light"><td>Drop 30%</td><td>71.0</td><td>136.3</td><td>-25.6%</td></tr>
                <tr class="has-background-info-light"><td>Drop 40%</td><td>68.6</td><td>119.8</td><td>-34.7%</td></tr>
                <tr class="has-background-success-light"><td><strong>Drop 50%</strong></td><td><strong>69.7</strong></td><td><strong>109.0</strong></td><td><strong>-40.5%</strong></td></tr>
                <tr class="has-background-danger-light"><td>Drop 60%</td><td>63.6</td><td>99.8</td><td>-45.6%</td></tr>
                <tr class="has-background-danger-light"><td>Drop 70%</td><td>53.3</td><td>89.5</td><td>-51.2%</td></tr>
                <tr class="has-background-danger-light"><td>Drop 80%</td><td>54.3</td><td>81.5</td><td>-55.5%</td></tr>
                <tr class="has-background-danger-light"><td>Drop 90%</td><td>46.7</td><td>73.8</td><td>-59.8%</td></tr>
              </tbody>
            </table>
          </div>
        </div>

        <h3 class="title is-4">VLA-Guided Planning</h3>
        <div class="content has-text-justified">
          <p>
            For policy-guided planning in long-horizon tasks including Real-world 
            tasks (Pick-and-Place and Close-Drawer) and LIBERO-10, Sparse imagination with 50% token drop 
            consistently matches Full-Patch performance with much lower planning overhead. 
          </p>
        </div>


        <div class="columns is-centered is-multiline">
          <div class="column is-4 has-text-centered">
            <video controls loop muted playsinline style="width: 100%; max-width: 320px;">
              <source src="./static/videos/demo_pickplace.mp4" type="video/mp4">
            </video>
            <p class="is-size-7">LeRobot PickPlace</p>
          </div>
          <div class="column is-4 has-text-centered">
            <video controls loop muted playsinline style="width: 100%; max-width: 320px;">
              <source src="./static/videos/demo_drawer.mp4" type="video/mp4">
            </video>
            <p class="is-size-7">LeRobot Drawer</p>
          </div>
          <div class="column is-4 has-text-centered">
            <video controls loop muted playsinline style="width: 100%; max-width: 320px;">
              <source src="./static/videos/demo_block_pushing.mp4" type="video/mp4">
            </video>
            <p class="is-size-7">Block Pushing</p>
          </div>
        </div>

        <div class="columns is-centered">
          <div class="column is-10 has-text-centered">
            <img src="./static/images/lerobot_libero_chart2.png" alt="LeRobot and LIBERO tradeoff"
                 style="max-height: 360px; width: auto; border: 1px solid #ddd; padding: 4px;"
                 onerror="this.src='https://via.placeholder.com/960x420?text=fig_lerobot_libero.png';">
                 <p class="is-size-6"><em>Performance vs inference-time in Real-world tasks and LIBERO-10.</em></p>
          </div>
        </div>

        <h3 class="title is-4">Why Random Sampling Works</h3>
        <div class="content has-text-justified">
          <p>
            Across token reduction baselines, random sampling remains highly competitive and often best on average. We attribute this to unbiased spatial coverage and reduced blind-spot risk in dynamic planning.
          </p>
        </div>


        <div class="columns is-centered" style="margin-top: 14px;">
          <div class="column is-10">
            <div class="columns is-mobile is-multiline is-variable is-2">
              <div class="column is-4-mobile is-2-desktop has-text-centered">
                <img src="./static/images/pat_random.png" alt="Random sampling pattern"
                     style="width: 100%; max-width: 140px; border: 1px solid #ddd; padding: 4px;"
                     onerror="this.src='https://via.placeholder.com/140x140?text=Random';">
                <p class="is-size-7">Random</p>
              </div>
              <div class="column is-4-mobile is-2-desktop has-text-centered">
                <img src="./static/images/pat_lhs.png" alt="LHS sampling pattern"
                     style="width: 100%; max-width: 140px; border: 1px solid #ddd; padding: 4px;"
                     onerror="this.src='https://via.placeholder.com/140x140?text=LHS';">
                <p class="is-size-7">LHS</p>
              </div>
              <div class="column is-4-mobile is-2-desktop has-text-centered">
                <img src="./static/images/pat_ltrp.png" alt="LTRP sampling pattern"
                     style="width: 100%; max-width: 140px; border: 1px solid #ddd; padding: 4px;"
                     onerror="this.src='https://via.placeholder.com/140x140?text=LTRP';">
                <p class="is-size-7">LTRP</p>
              </div>
              <div class="column is-4-mobile is-2-desktop has-text-centered">
                <img src="./static/images/pat_attn.png" alt="Attention-Encoder sampling pattern"
                     style="width: 100%; max-width: 140px; border: 1px solid #ddd; padding: 4px;"
                     onerror="this.src='https://via.placeholder.com/140x140?text=Attn-Enc';">
                <p class="is-size-7">Attention-Encoder</p>
              </div>
              <div class="column is-4-mobile is-2-desktop has-text-centered">
                <img src="./static/images/pat_star.png" alt="STAR sampling pattern"
                     style="width: 100%; max-width: 140px; border: 1px solid #ddd; padding: 4px;"
                     onerror="this.src='https://via.placeholder.com/140x140?text=STAR';">
                <p class="is-size-7">STAR</p>
              </div>
              <div class="column is-4-mobile is-2-desktop has-text-centered">
                <img src="./static/images/pat_attnwm.png" alt="Attention-WM sampling pattern"
                     style="width: 100%; max-width: 140px; border: 1px solid #ddd; padding: 4px;"
                     onerror="this.src='https://via.placeholder.com/140x140?text=Attn-WM';">
                <p class="is-size-7">Attention-WM</p>
              </div>
            </div>
          </div>
        </div>

        <div class="columns is-centered">
          <div class="column is-8">
            <table class="table is-bordered is-striped is-hoverable is-fullwidth" style="font-size: 0.9em;">
              <thead>
                <tr class="has-background-light">
                  <th>Method Family</th>
                  <th>Representative</th>
                  <th>Avg. Success (%)</th>
                </tr>
              </thead>
              <tbody>
                <tr class="has-background-success-light"><td rowspan="3">Random Sampling</td><td><strong>Random</strong></td><td><strong>66.7</strong></td></tr>
                <tr><td>Fixed</td><td>64.3</td></tr>
                <tr><td>LHS</td><td>65.7</td></tr>
                <tr><td>Learning-Based Pruning</td><td>LTRP</td><td>59.5</td></tr>
                <tr><td rowspan="3">Attention-Based Pruning</td><td>Attention-Encoder</td><td>63.0</td></tr>
                <tr><td>STAR</td><td>61.4</td></tr>
                <tr><td>Attention-WM</td><td>64.0</td></tr>
                <tr><td>Cluster and Merging</td><td>ATC</td><td>41.7</td></tr>
              </tbody>
            </table>
          </div>
        </div>


        <h3 class="title is-4">Information Sufficiency (nHSIC and Attentive Probing)</h3>
        <div class="content has-text-justified">
          <p>
            We further verify that sparse token subsets retain useful state information.
             nHSIC remains high even under substantial dropout, and attentive probing shows
              that random token subsets keep strong predictive signal. Notably, even a single 
              random token can be comparable to the CLS token in probing performance.
          </p>
        </div>

        <div class="columns is-centered">
          <div class="column is-6 has-text-centered">
            <img src="./static/images/hsic.png" alt="nHSIC under token dropout"
                 style="max-height: 320px; width: auto; border: 1px solid #ddd; padding: 4px;"
                 onerror="this.src='https://via.placeholder.com/640x360?text=hsic.png';">
            <p class="is-size-6"><em>nHSIC between visual tokens and environment states.</em></p>
          </div>
          <div class="column is-6 has-text-centered">
            <img src="./static/images/probing.png" alt="Attentive probing results"
                 style="max-height: 320px; width: auto; border: 1px solid #ddd; padding: 4px;"
                 onerror="this.src='https://via.placeholder.com/640x360?text=probing.png';">
            <p class="is-size-6"><em>Attentive probing validation loss under token dropout.</em></p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Conclusion</h2>
        <div class="content has-text-justified">
          <p>
            Sparse imagination reduces world-model planning cost by dropping visual tokens at inference while preserving performance across simulation and real-world tasks. The method is simple, robust, and broadly compatible with transformer-based visual planners.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{chun2026sparseimagination,
  title   = {Sparse Imagination for Efficient Visual World Model Planning},
  author  = {Junha Chun and Youngjoon Jeong and Taesup Kim},
  journal = {ICLR},
  year    = {2026}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="#" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website template was adapted from <a href="https://nerfies.github.io/">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
